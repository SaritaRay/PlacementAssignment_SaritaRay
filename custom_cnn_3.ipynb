{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Question 3 -**\n",
        "Train a Pure CNN with less than 10000 trainable parameters using the MNIST\n",
        "Dataset having minimum validation accuracy of 99.40%\n",
        "\n",
        "**Note -**\n",
        "\n",
        "1. Code comments should be given for proper code understanding.\n",
        "2. Implement in both PyTorch and Tensorflow respectively"
      ],
      "metadata": {
        "id": "GdnIMy2y46E5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Tensorflow"
      ],
      "metadata": {
        "id": "yDt2ocO8JvqL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Add, Dense, Flatten, Dropout\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation"
      ],
      "metadata": {
        "id": "an-oznSn5AbZ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the dataset and perform splitting\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrsgu3lz5hcA",
        "outputId": "52647de2-1353-40bd-b9c4-cc3cb55a3c5b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Peforming reshaping operation\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)"
      ],
      "metadata": {
        "id": "HPjmE1wq5k1A"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalization\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255"
      ],
      "metadata": {
        "id": "JKxpulmY5oFa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One Hot Encoding\n",
        "y_train = keras.utils.to_categorical(y_train, 10)\n",
        "y_test = keras.utils.to_categorical(y_test, 10)"
      ],
      "metadata": {
        "id": "RSh_vZG15qOy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build the model object\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(8,(3, 3), activation ='relu',input_shape = (28,28,1))) # Channel dimension = 26*26*10 , receptive field 3*3\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Conv2D(16,(3, 3), activation ='relu'))                      # Channel dimension = 24*24*16 , receptive field 5*5\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Conv2D(8,(1,1), activation ='relu'))                        # Channel dimension = 24*24*10 , receptive field 5*5\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))                              # Channel dimension = 12*12*10 , receptive field 10*10\n",
        "\n",
        "model.add(Conv2D(10,(3,3), activation ='relu'))                       # Channel dimension = 10*10*16 , receptive field 12*12\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Conv2D(10,(3,3), activation ='relu'))                       # Channel dimension = 8*8*16 , receptive field 14*14\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Conv2D(16,(3,3), activation ='relu'))                       # Channel dimension = 6*6*16 , receptive field 16*16\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Conv2D(16,(3,3), activation ='relu'))                       # Channel dimension = 4*4*16 , receptive field 18*18\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Conv2D(10,4,4))                                             # Channel dimension 4*4 to see the complete image \n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Activation('softmax'))"
      ],
      "metadata": {
        "id": "cH0f_mZN5tXw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YgBtGy353XL",
        "outputId": "f89c04be-f0b3-45ca-a2db-939e578280c4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 8)         80        \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 26, 26, 8)        32        \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 26, 26, 8)         0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 24, 24, 16)        1168      \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 24, 24, 16)       64        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 24, 24, 16)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 24, 24, 8)         136       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 12, 12, 8)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 10, 10, 10)        730       \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 10, 10, 10)       40        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 10, 10, 10)        0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 8, 8, 10)          910       \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 8, 8, 10)         40        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 8, 8, 10)          0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 6, 6, 16)          1456      \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 6, 6, 16)         64        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 6, 6, 16)          0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 4, 4, 16)          2320      \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 4, 4, 16)         64        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 4, 4, 16)          0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 1, 1, 10)          2570      \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 10)                0         \n",
            "                                                                 \n",
            " activation (Activation)     (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,674\n",
            "Trainable params: 9,522\n",
            "Non-trainable params: 152\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(loss =keras.metrics.categorical_crossentropy,optimizer=keras.optimizers.Adam(),metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "t7Xz_seN53aQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train,y_train,batch_size=64, epochs=30, validation_data=(X_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PP2L3Jap9FNV",
        "outputId": "66b6863e-1e1d-4cd2-bdb2-dc68b757b9ac"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "938/938 [==============================] - 17s 8ms/step - loss: 0.3235 - accuracy: 0.8997 - val_loss: 0.0907 - val_accuracy: 0.9727\n",
            "Epoch 2/30\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.1028 - accuracy: 0.9675 - val_loss: 0.0566 - val_accuracy: 0.9816\n",
            "Epoch 3/30\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 0.0765 - accuracy: 0.9757 - val_loss: 0.0422 - val_accuracy: 0.9862\n",
            "Epoch 4/30\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0644 - accuracy: 0.9797 - val_loss: 0.0414 - val_accuracy: 0.9869\n",
            "Epoch 5/30\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 0.0575 - accuracy: 0.9825 - val_loss: 0.0472 - val_accuracy: 0.9845\n",
            "Epoch 6/30\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0527 - accuracy: 0.9840 - val_loss: 0.0309 - val_accuracy: 0.9915\n",
            "Epoch 7/30\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 0.0475 - accuracy: 0.9853 - val_loss: 0.0317 - val_accuracy: 0.9898\n",
            "Epoch 8/30\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0461 - accuracy: 0.9856 - val_loss: 0.0327 - val_accuracy: 0.9904\n",
            "Epoch 9/30\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 0.0443 - accuracy: 0.9863 - val_loss: 0.0337 - val_accuracy: 0.9894\n",
            "Epoch 10/30\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0387 - accuracy: 0.9877 - val_loss: 0.0274 - val_accuracy: 0.9917\n",
            "Epoch 11/30\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 0.0389 - accuracy: 0.9875 - val_loss: 0.0270 - val_accuracy: 0.9912\n",
            "Epoch 12/30\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0370 - accuracy: 0.9883 - val_loss: 0.0249 - val_accuracy: 0.9917\n",
            "Epoch 13/30\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 0.0369 - accuracy: 0.9884 - val_loss: 0.0240 - val_accuracy: 0.9933\n",
            "Epoch 14/30\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0352 - accuracy: 0.9886 - val_loss: 0.0257 - val_accuracy: 0.9922\n",
            "Epoch 15/30\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0338 - accuracy: 0.9892 - val_loss: 0.0270 - val_accuracy: 0.9924\n",
            "Epoch 16/30\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0339 - accuracy: 0.9888 - val_loss: 0.0244 - val_accuracy: 0.9922\n",
            "Epoch 17/30\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 0.0314 - accuracy: 0.9900 - val_loss: 0.0255 - val_accuracy: 0.9922\n",
            "Epoch 18/30\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0320 - accuracy: 0.9898 - val_loss: 0.0237 - val_accuracy: 0.9928\n",
            "Epoch 19/30\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 0.0304 - accuracy: 0.9899 - val_loss: 0.0232 - val_accuracy: 0.9926\n",
            "Epoch 20/30\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0292 - accuracy: 0.9908 - val_loss: 0.0255 - val_accuracy: 0.9917\n",
            "Epoch 21/30\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 0.0301 - accuracy: 0.9901 - val_loss: 0.0292 - val_accuracy: 0.9907\n",
            "Epoch 22/30\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0282 - accuracy: 0.9904 - val_loss: 0.0233 - val_accuracy: 0.9926\n",
            "Epoch 23/30\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 0.0275 - accuracy: 0.9914 - val_loss: 0.0221 - val_accuracy: 0.9928\n",
            "Epoch 24/30\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0263 - accuracy: 0.9916 - val_loss: 0.0290 - val_accuracy: 0.9912\n",
            "Epoch 25/30\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 0.0285 - accuracy: 0.9902 - val_loss: 0.0231 - val_accuracy: 0.9924\n",
            "Epoch 26/30\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0277 - accuracy: 0.9910 - val_loss: 0.0200 - val_accuracy: 0.9933\n",
            "Epoch 27/30\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0246 - accuracy: 0.9920 - val_loss: 0.0261 - val_accuracy: 0.9922\n",
            "Epoch 28/30\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 0.0248 - accuracy: 0.9920 - val_loss: 0.0233 - val_accuracy: 0.9929\n",
            "Epoch 29/30\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0251 - accuracy: 0.9916 - val_loss: 0.0216 - val_accuracy: 0.9929\n",
            "Epoch 30/30\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0246 - accuracy: 0.9918 - val_loss: 0.0241 - val_accuracy: 0.9929\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0v11Bxm53dY",
        "outputId": "33ce8b8d-c00e-475e-8a5c-0ae4345c7e99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0230 - accuracy: 0.9933\n",
            "Test accuracy: 0.9933000206947327\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Torch"
      ],
      "metadata": {
        "id": "Pc8-BIz1J0zP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchsummary import summary"
      ],
      "metadata": {
        "id": "UvWfMsKNwzc9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "Z3k1s8Trw24b"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and normalize dataset\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "  transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True,download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', train=False,download=True, transform=transform)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_HrUGcRw4ZZ",
        "outputId": "b868b9ea-d0c3-4516-ba52-29e5fd874ca2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 267869203.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 123607850.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 126862173.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 4542/4542 [00:00<00:00, 6968006.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data loaders\n",
        "batch_size = 64\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "loqqotKuw79F"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the size of the loaded data\n",
        "print(\"Training data size:\", len(train_dataset))\n",
        "print(\"Testing data size:\", len(test_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Kn-TT3HxAyp",
        "outputId": "69aacd18-931f-47fd-b180-38cee0241fda"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data size: 60000\n",
            "Testing data size: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "num_epochs = 30\n",
        "batch_size = 64\n",
        "learning_rate = 0.001"
      ],
      "metadata": {
        "id": "H-RWvIJaxEQq"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(1, 8, 3)  # input_channel=1, output_channel=8, kernel_size=3x3\n",
        "        self.batchnorm1 = nn.BatchNorm2d(8)\n",
        "        self.dropout1 = nn.Dropout(0.1)\n",
        "        \n",
        "        self.conv2 = nn.Conv2d(8, 16, 3)  # input_channel=8, output_channel=16, kernel_size=3x3\n",
        "        self.batchnorm2 = nn.BatchNorm2d(16)\n",
        "        self.dropout2 = nn.Dropout(0.1)\n",
        "        \n",
        "        self.conv3 = nn.Conv2d(16, 8, 1)  # input_channel=16, output_channel=8, kernel_size=1x1\n",
        "        self.maxpool = nn.MaxPool2d(2)  # Max pooling with kernel_size=2x2\n",
        "        \n",
        "        self.conv4 = nn.Conv2d(8, 10, 3)  # input_channel=8, output_channel=10, kernel_size=3x3\n",
        "        self.batchnorm3 = nn.BatchNorm2d(10)\n",
        "        self.dropout3 = nn.Dropout(0.1)\n",
        "        \n",
        "        self.conv5 = nn.Conv2d(10, 10, 3)  # input_channel=10, output_channel=10, kernel_size=3x3\n",
        "        self.batchnorm4 = nn.BatchNorm2d(10)\n",
        "        self.dropout4 = nn.Dropout(0.1)\n",
        "        \n",
        "        self.conv6 = nn.Conv2d(10, 16, 3)  # input_channel=10, output_channel=16, kernel_size=3x3\n",
        "        self.batchnorm5 = nn.BatchNorm2d(16)\n",
        "        self.dropout5 = nn.Dropout(0.1)\n",
        "        \n",
        "        self.conv7 = nn.Conv2d(16, 16, 3)  # input_channel=16, output_channel=16, kernel_size=3x3\n",
        "        self.batchnorm6 = nn.BatchNorm2d(16)\n",
        "        self.dropout6 = nn.Dropout(0.1)\n",
        "        \n",
        "        self.conv8 = nn.Conv2d(16, 10, 4)  # input_channel=16, output_channel=10, kernel_size=4x4\n",
        "        \n",
        "        self.flatten = nn.Flatten()\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = nn.ReLU()(self.conv1(x))\n",
        "        x = self.batchnorm1(x)\n",
        "        x = self.dropout1(x)\n",
        "        \n",
        "        x = nn.ReLU()(self.conv2(x))\n",
        "        x = self.batchnorm2(x)\n",
        "        x = self.dropout2(x)\n",
        "        \n",
        "        x = nn.ReLU()(self.conv3(x))\n",
        "        x = self.maxpool(x)\n",
        "        \n",
        "        x = nn.ReLU()(self.conv4(x))\n",
        "        x = self.batchnorm3(x)\n",
        "        x = self.dropout3(x)\n",
        "        \n",
        "        x = nn.ReLU()(self.conv5(x))\n",
        "        x = self.batchnorm4(x)\n",
        "        x = self.dropout4(x)\n",
        "        \n",
        "        x = nn.ReLU()(self.conv6(x))\n",
        "        x = self.batchnorm5(x)\n",
        "        x = self.dropout5(x)\n",
        "        \n",
        "        x = nn.ReLU()(self.conv7(x))\n",
        "        x = self.batchnorm6(x)\n",
        "        x = self.dropout6(x)\n",
        "        \n",
        "        x = self.conv8(x)\n",
        "        \n",
        "        x = self.flatten(x)\n",
        "        x = self.softmax(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "QcUqXVWvxGit"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model\n",
        "model = Model().to(device)"
      ],
      "metadata": {
        "id": "4WFz1MGlxaf7"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the model summary\n",
        "summary(model, (1, 28, 28))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFP_DLL5xgGb",
        "outputId": "5a64e9e8-6d6a-4964-ec86-9b823592f8d7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 8, 26, 26]              80\n",
            "       BatchNorm2d-2            [-1, 8, 26, 26]              16\n",
            "           Dropout-3            [-1, 8, 26, 26]               0\n",
            "            Conv2d-4           [-1, 16, 24, 24]           1,168\n",
            "       BatchNorm2d-5           [-1, 16, 24, 24]              32\n",
            "           Dropout-6           [-1, 16, 24, 24]               0\n",
            "            Conv2d-7            [-1, 8, 24, 24]             136\n",
            "         MaxPool2d-8            [-1, 8, 12, 12]               0\n",
            "            Conv2d-9           [-1, 10, 10, 10]             730\n",
            "      BatchNorm2d-10           [-1, 10, 10, 10]              20\n",
            "          Dropout-11           [-1, 10, 10, 10]               0\n",
            "           Conv2d-12             [-1, 10, 8, 8]             910\n",
            "      BatchNorm2d-13             [-1, 10, 8, 8]              20\n",
            "          Dropout-14             [-1, 10, 8, 8]               0\n",
            "           Conv2d-15             [-1, 16, 6, 6]           1,456\n",
            "      BatchNorm2d-16             [-1, 16, 6, 6]              32\n",
            "          Dropout-17             [-1, 16, 6, 6]               0\n",
            "           Conv2d-18             [-1, 16, 4, 4]           2,320\n",
            "      BatchNorm2d-19             [-1, 16, 4, 4]              32\n",
            "          Dropout-20             [-1, 16, 4, 4]               0\n",
            "           Conv2d-21             [-1, 10, 1, 1]           2,570\n",
            "          Flatten-22                   [-1, 10]               0\n",
            "          Softmax-23                   [-1, 10]               0\n",
            "================================================================\n",
            "Total params: 9,522\n",
            "Trainable params: 9,522\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.44\n",
            "Params size (MB): 0.04\n",
            "Estimated Total Size (MB): 0.47\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "6AcJBXlixidX"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Training\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # Move inputs and labels to the same device as the model\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "id": "k2_o9jOoJ3lf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26b94d28-ccb4-4cb8-8dda-10b8c37c94fb"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        \n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Test Accuracy: {accuracy:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGbhoz4Zzmjr",
        "outputId": "7c4ef7b4-1816-4c1c-da2f-834b7a6abbdc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 99.09%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "20D7Jo_BhQJk"
      },
      "execution_count": 21,
      "outputs": []
    }
  ]
}