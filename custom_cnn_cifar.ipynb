{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MhKzUVn3XuXd"
   },
   "source": [
    "**Question 2 -**\n",
    "Implement 5 different CNN architectures with a comparison table for CIFAR 10\n",
    "dataset using the PyTorch library\n",
    "\n",
    "**Note -**\n",
    "1. The model parameters for each architecture should not be more than 10000 parameters.\n",
    "\n",
    "2. Code comments should be given for proper code understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "slGYGJ-CZAuM"
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fzD3dWtOrRZg"
   },
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vbIcwOyVbgrQ"
   },
   "outputs": [],
   "source": [
    "# Load and normalize CIFAR10\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),# Convert PIL image to PyTorch tensor\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) # Normalize the image pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iKz8denhbC4K",
    "outputId": "9e8dcc12-b4a7-419c-bafe-f8f515c06304"
   },
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,download=True, transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5qfstii-cpD3",
    "outputId": "e9ee9230-9add-4ad8-dd62-c1d533039ef3"
   },
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "batch_size = 128\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Check the size of the loaded data\n",
    "print(\"Training data size:\", len(train_dataset))\n",
    "print(\"Testing data size:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4le4Jvcmc6xG"
   },
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 473
    },
    "id": "aiW8ao-Uc64_",
    "outputId": "70aeb8cd-9113-41a7-de0a-2e053c7581ed"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WdwkEurnrinF"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_epochs = 30\n",
    "batch_size = 128\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kSRl7vrXxMaf"
   },
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HPghTGhBtKNg"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 6, kernel_size=5)  # Modified input channels to 3\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(16 * 5 * 5, 10)  # Adjusted input size to 16*5*5\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EvvQrP2XdgEb"
   },
   "outputs": [],
   "source": [
    "# Create the LeNet-5 model\n",
    "model1 = Model().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CEeeFv0frn0t",
    "outputId": "ab9f4e8f-18f7-49b7-bbe3-2a7a2aa3db9c"
   },
   "outputs": [],
   "source": [
    "# Print the model summary\n",
    "summary(model1, (3, 32, 32))  # Assuming RGB images of size 32x32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mxJIT7Kxrn4o"
   },
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model1.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "afCGR6kDrn-B",
    "outputId": "13fc6bb1-237f-4344-ba94-73ca12917ec5"
   },
   "outputs": [],
   "source": [
    "#Model Training\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Move inputs and labels to the same device as the model\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model1(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oNZl7QDwr_H_",
    "outputId": "a86ad891-1bf6-4809-e7bc-c42db7b6840b"
   },
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "model1.eval()  # Set the model to evaluation mode\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model1(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "acc_model1 = 100 * correct / total\n",
    "print(f'Test Accuracy: {acc_model1:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OHrzseKOySWO"
   },
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WZY3D5elyT_s"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 8, kernel_size=3)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.batchnorm1 = nn.BatchNorm2d(8, track_running_stats=True)\n",
    "        self.dropout1 = nn.Dropout2d(0.1)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=3)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.batchnorm2 = nn.BatchNorm2d(16, track_running_stats=True)\n",
    "        self.dropout2 = nn.Dropout2d(0.1)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(16, 8, kernel_size=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(8, 10, kernel_size=3)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.batchnorm3 = nn.BatchNorm2d(10, track_running_stats=True)\n",
    "        self.dropout3 = nn.Dropout2d(0.1)\n",
    "\n",
    "        self.conv5 = nn.Conv2d(10, 10, kernel_size=3)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.batchnorm4 = nn.BatchNorm2d(10, track_running_stats=True)\n",
    "        self.dropout4 = nn.Dropout2d(0.1)\n",
    "\n",
    "        self.conv6 = nn.Conv2d(10, 10, kernel_size=3)\n",
    "        self.relu6 = nn.ReLU()\n",
    "        self.batchnorm5 = nn.BatchNorm2d(10, track_running_stats=True)\n",
    "        self.dropout5 = nn.Dropout2d(0.1)\n",
    "\n",
    "        self.conv7 = nn.Conv2d(10, 10, kernel_size=3)\n",
    "        self.relu7 = nn.ReLU()\n",
    "        self.batchnorm6 = nn.BatchNorm2d(10, track_running_stats=True)\n",
    "        self.dropout6 = nn.Dropout2d(0.1)\n",
    "\n",
    "        self.conv8 = nn.Conv2d(10, 10, kernel_size=4)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.dropout3(x)\n",
    "\n",
    "        x = self.conv5(x)\n",
    "        x = self.relu5(x)\n",
    "        x = self.batchnorm4(x)\n",
    "        x = self.dropout4(x)\n",
    "\n",
    "        x = self.conv6(x)\n",
    "        x = self.relu6(x)\n",
    "        x = self.batchnorm5(x)\n",
    "        x = self.dropout5(x)\n",
    "\n",
    "        x = self.conv7(x)\n",
    "        x = self.relu7(x)\n",
    "        x = self.batchnorm6(x)\n",
    "        x = self.dropout6(x)\n",
    "\n",
    "        x = self.conv8(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p9nrAxWxzGED"
   },
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model2 = Model().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4vkSZSG8zjBH",
    "outputId": "186943c1-1519-4cb1-decf-f7ef8f39a08f"
   },
   "outputs": [],
   "source": [
    "# Print the model summary\n",
    "summary(model2, (3, 32, 32))  # Assuming RGB images of size 32x32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cciK0lrjzjEe"
   },
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model2.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h1xdJJ7rz8Ty",
    "outputId": "2fa8419f-c26e-4639-c57a-f71b8c67215b"
   },
   "outputs": [],
   "source": [
    "#Model Training\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Move inputs and labels to the same device as the model\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model2(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TBgH380tzjKd",
    "outputId": "0f7f327b-f70b-41ad-e182-aff6149f564d"
   },
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "model2.eval()  # Set the model to evaluation mode\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model2(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "acc_model2 = 100 * correct / total\n",
    "print(f'Test Accuracy: {acc_model2:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8unMtzd2o1K"
   },
   "source": [
    "## Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Dih5h8I2FZn"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 8, kernel_size=3) # Channel dimension = 30*30*10 , receptive field 3*3\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.batchnorm1 = nn.BatchNorm2d(8,track_running_stats=True)\n",
    "        self.dropout1 = nn.Dropout2d(0.1)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=3) # Channel dimension = 24*24*10 , receptive field 5*5\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.batchnorm2 = nn.BatchNorm2d(16,track_running_stats=True)\n",
    "        self.dropout2 = nn.Dropout2d(0.1)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(16, 8, kernel_size=1) # Channel dimension = 24*24*10 , receptive field 5*5\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2) # Channel dimension = 12*12*10 , receptive field 10*10\n",
    "\n",
    "        self.conv4 = nn.Conv2d(8, 8, kernel_size=3) # Channel dimension = 10*10*10 , receptive field 12*12\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.batchnorm3 = nn.BatchNorm2d(8,track_running_stats=True)\n",
    "        self.dropout3 = nn.Dropout2d(0.1)\n",
    "\n",
    "        self.conv5 = nn.Conv2d(8, 8, kernel_size=3) # Channel dimension = 8*8*10 , receptive field 14*14\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.batchnorm4 = nn.BatchNorm2d(8,track_running_stats=True)\n",
    "        self.dropout4 = nn.Dropout2d(0.1)\n",
    "\n",
    "        self.conv6 = nn.Conv2d(8, 10, kernel_size=3) # Channel dimension = 6*6*10 , receptive field 16*16\n",
    "        self.relu6 = nn.ReLU()\n",
    "        self.batchnorm5 = nn.BatchNorm2d(10,track_running_stats=True)\n",
    "        self.dropout5 = nn.Dropout2d(0.1)\n",
    "\n",
    "        self.conv7 = nn.Conv2d(10, 10, kernel_size=3) # Channel dimension = 4*4*10 , receptive field 18*18\n",
    "        self.relu7 = nn.ReLU()\n",
    "        self.batchnorm6 = nn.BatchNorm2d(10,track_running_stats=True)\n",
    "        self.dropout6 = nn.Dropout2d(0.1)\n",
    "\n",
    "        #self.conv8 = nn.Conv2d(10, 10, kernel_size=4) # Channel dimension = 24*24*10 , receptive field 5*5\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.dropout3(x)\n",
    "\n",
    "        x = self.conv5(x)\n",
    "        x = self.relu5(x)\n",
    "        x = self.batchnorm4(x)\n",
    "        x = self.dropout4(x)\n",
    "\n",
    "        x = self.conv6(x)\n",
    "        x = self.relu6(x)\n",
    "        x = self.batchnorm5(x)\n",
    "        x = self.dropout5(x)\n",
    "\n",
    "        x = self.conv7(x)\n",
    "        x = self.relu7(x)\n",
    "        x = self.batchnorm6(x)\n",
    "        x = self.dropout6(x)\n",
    "\n",
    "        #x = self.conv8(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L8U4vkAP2r3t"
   },
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model3 = Model().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f3B4uKZS2xFL",
    "outputId": "dd7083b4-105b-4389-9945-36e167cb19ee"
   },
   "outputs": [],
   "source": [
    "# Print the model summary\n",
    "summary(model3, (3, 32, 32))  # Assuming RGB images of size 32x32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "phWuCBk523L4"
   },
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model3.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JCcROZfO3Hu3",
    "outputId": "4151cfc2-6854-4cf8-8ad7-abe77a6d00d2"
   },
   "outputs": [],
   "source": [
    "#Model Training\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Move inputs and labels to the same device as the model\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model3(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EftVeEU13NG6",
    "outputId": "b2f6b790-d2b1-4fc9-9400-3b44d7b2552b"
   },
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "model3.eval()  # Set the model to evaluation mode\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model3(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "acc_model3 = 100 * correct / total\n",
    "print(f'Test Accuracy: {acc_model3:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6sgfuolO35Jx"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame\n",
    "data = {\n",
    "    'Architecture': ['Model1', 'Model2','Model3'],\n",
    "    'Test Accuracy': [acc_model1,acc_model2,acc_model3]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LhTnTADQUaBM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
